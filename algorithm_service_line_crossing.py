#!/usr/bin/env python3
"""
YOLOv11x ç»Šçº¿äººæ•°ç»Ÿè®¡ç®—æ³•æœåŠ¡
ä¸“é—¨ç”¨äºç»Šçº¿æ£€æµ‹å’Œè·¨çº¿è®¡æ•°
ç¬¦åˆEasyDarwinæ™ºèƒ½åˆ†ææ’ä»¶è§„èŒƒ
"""
import os
import argparse
import json
import time
import threading
import signal
import sys
import queue
import socketserver
from concurrent.futures import ThreadPoolExecutor
from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import urlparse, parse_qs
import requests
import urllib.request
import numpy as np
import cv2
from PIL import Image, ImageDraw, ImageFont
from ultralytics import YOLO
from collections import defaultdict
from pathlib import Path
from datetime import datetime
import uuid

# å°è¯•å¯¼å…¥ ThreadingHTTPServerï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
try:
    from http.server import ThreadingHTTPServer
except ImportError:
    # Python < 3.7 çš„å…¼å®¹æ–¹æ¡ˆ
    class ThreadingHTTPServer(socketserver.ThreadingMixIn, HTTPServer):
        daemon_threads = True

# å…¨å±€é…ç½®
CONFIG = {
    'service_id': 'yolo11x_line_crossing',
    'name': 'YOLOv11xç»Šçº¿äººæ•°ç»Ÿè®¡ç®—æ³•',
    'version': '1.0.0',
    'model_path': '/cv_space/NWPU-Crowd/runs/exp_yolo11x3/weights/best.pt',
    'task_types': ['ç»Šçº¿äººæ•°ç»Ÿè®¡'],
    'port': 7903,  # ä½¿ç”¨ä¸åŒçš„ç«¯å£
    'host': '0.0.0.0',
    'easydarwin_url': 'http://localhost:5066',
    'heartbeat_interval': 30,  # ç§’
    # æ‰¹å¤„ç†é…ç½®
    'batch_size': 8,
    'batch_timeout': 0.1,
    'enable_batching': True,
    'max_queue_size': 100,
    # å¯è§†åŒ–é…ç½®
    'enable_video': False,
}

# å…¨å±€å˜é‡
MODEL = None
RUNNING = True
HEARTBEAT_THREAD = None
TRACKER_MANAGER = None
TRACKER_LOCK = threading.Lock()
VIDEO_WRITERS = {}
VIDEO_WRITERS_LOCK = threading.Lock()

# æ‰¹å¤„ç†ç›¸å…³
BATCH_PROCESSOR = None
BATCH_PROCESSOR_THREAD = None
INFERENCE_RESULTS = {}
INFERENCE_EVENTS = {}
BATCH_STATS = {
    'total_requests': 0,
    'total_batches': 0,
    'total_inference_time': 0.0,
    'avg_batch_size': 0.0,
    'max_batch_size': 0,
    'last_inference_time': 0.0,  # æœ€è¿‘ä¸€æ¬¡æ¨ç†æ—¶é—´ï¼ˆmsï¼‰
    'last_total_time': 0.0,      # æœ€è¿‘ä¸€æ¬¡æ€»è€—æ—¶ï¼ˆmsï¼‰
}

# ç»Šçº¿å‘Šè­¦ç›¸å…³ï¼ˆå¢é‡å‘Šè­¦æœºåˆ¶ï¼‰
LAST_CROSSING_COUNTS = {}
LAST_CROSSING_COUNTS_LOCK = threading.Lock()


def point_in_polygon(point, polygon):
    """
    åˆ¤æ–­ç‚¹æ˜¯å¦åœ¨å¤šè¾¹å½¢å†…ï¼ˆå°„çº¿æ³•ï¼‰
    point: (x, y)
    polygon: [(x1, y1), (x2, y2), ...]
    """
    x, y = point
    n = len(polygon)
    inside = False
    
    p1x, p1y = polygon[0]
    for i in range(1, n + 1):
        p2x, p2y = polygon[i % n]
        if y > min(p1y, p2y):
            if y <= max(p1y, p2y):
                if x <= max(p1x, p2x):
                    if p1y != p2y:
                        xinters = (y - p1y) * (p2x - p1x) / (p2y - p1y) + p1x
                    if p1x == p2x or x <= xinters:
                        inside = not inside
        p1x, p1y = p2x, p2y
    
    return inside


def filter_objects_by_region(objects, regions_or_config, image_size):
    """
    æ ¹æ®åŒºåŸŸè¿‡æ»¤æ£€æµ‹å¯¹è±¡ï¼ˆæ”¯æŒçŸ©å½¢ã€å¤šè¾¹å½¢ï¼Œæ”¯æŒå½’ä¸€åŒ–/ç”»å¸ƒåæ ‡ï¼‰
    objects:    æ£€æµ‹åˆ°çš„å¯¹è±¡åˆ—è¡¨
    regions_or_config: åŒºåŸŸé…ç½®åˆ—è¡¨æˆ–å®Œæ•´ç®—æ³•é…ç½®
    image_size: (width, height)
    è¿”å›:       è¿‡æ»¤åçš„å¯¹è±¡åˆ—è¡¨
    """
    if not regions_or_config:
        return objects
    
    algo_config = regions_or_config if isinstance(regions_or_config, dict) else None
    regions = algo_config.get('regions', []) if algo_config else regions_or_config
    
    if not regions:
        return objects
    
    # åªè€ƒè™‘å¯ç”¨çš„éç»Šçº¿åŒºåŸŸ
    enabled_regions = [
        r for r in regions
        if r.get('enabled', True) and r.get('type') not in ['line']
    ]
    
    if not enabled_regions:
        # æ²¡æœ‰å¯ç”¨çš„æ£€æµ‹åŒºåŸŸï¼Œè¿”å›æ‰€æœ‰å¯¹è±¡
        return objects
    
    width, height = image_size
    filtered_objects = []
    
    default_coordinate_type = ''
    canvas_size = {}
    if algo_config:
        default_coordinate_type = (algo_config.get('coordinate_type') or '').lower()
        canvas_size = algo_config.get('canvas_size') or {}
    
    canvas_width = canvas_size.get('width') or width
    canvas_height = canvas_size.get('height') or height

    def convert_point(point, coordinate_type_override=None):
        if point is None or len(point) < 2:
            return None
        
        x, y = point[0], point[1]
        coord_type = (coordinate_type_override or '').lower()
        if not coord_type:
            coord_type = default_coordinate_type
        
        if coord_type in ('normalized', 'relative'):
            return x * width, y * height
        
        if coord_type in ('canvas', 'design', 'ui'):
            if canvas_width and canvas_height:
                scale_x = width / canvas_width
                scale_y = height / canvas_height
                return x * scale_x, y * scale_y
            return x, y
        
        if coord_type in ('pixel', 'pixels', 'absolute'):
            return x, y
        
        if isinstance(x, (int, float)) and isinstance(y, (int, float)):
            if 0.0 <= x <= 1.0 and 0.0 <= y <= 1.0:
                return x * width, y * height
        return x, y

    for obj in objects:
        bbox = obj['bbox']
        # è®¡ç®—ç‰©ä½“ä¸­å¿ƒç‚¹ï¼ˆåŸå§‹åæ ‡ï¼‰
        center_x_raw = (bbox[0] + bbox[2]) / 2
        center_y_raw = (bbox[1] + bbox[3]) / 2
        
        # åˆ¤æ–­bboxæ˜¯å¦ä¸ºå½’ä¸€åŒ–åæ ‡ï¼Œå¹¶è½¬æ¢ä¸ºåƒç´ åæ ‡
        if all(0 <= coord <= 1 for coord in bbox):
            # å½’ä¸€åŒ–åæ ‡ï¼Œè½¬æ¢ä¸ºåƒç´ åæ ‡
            center_x = center_x_raw * width
            center_y = center_y_raw * height
        else:
            # å·²ç»æ˜¯åƒç´ åæ ‡
            center_x = center_x_raw
            center_y = center_y_raw
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ä»»ä½•ä¸€ä¸ªåŒºåŸŸå†…
        in_any_region = False
        for region in enabled_regions:
            region_type = region.get('type')
            points = region.get('points', [])
            region_coord_type = (region.get('coordinate_type') or '').lower()
            region_threshold = None
            properties = region.get('properties') or {}
            if isinstance(properties, dict):
                region_threshold = properties.get('threshold')
            if region_threshold is not None:
                try:
                    if float(obj.get('confidence', 0.0)) < float(region_threshold):
                        continue
                except Exception:
                    continue
            
            if region_type == 'rectangle' and len(points) >= 2:
                # çŸ©å½¢åŒºåŸŸï¼špoints[0] æ˜¯å·¦ä¸Šè§’ï¼Œpoints[1] æ˜¯å³ä¸‹è§’
                p1, p2 = points[0], points[1]
                
                converted_p1 = convert_point(p1, region_coord_type)
                converted_p2 = convert_point(p2, region_coord_type)
                if not converted_p1 or not converted_p2:
                    continue
                x1, y1 = converted_p1
                x2, y2 = converted_p2
                
                # ç¡®ä¿ x1 < x2, y1 < y2
                x1, x2 = min(x1, x2), max(x1, x2)
                y1, y2 = min(y1, y2), max(y1, y2)
                
                # åˆ¤æ–­ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨çŸ©å½¢å†…
                if x1 <= center_x <= x2 and y1 <= center_y <= y2:
                    in_any_region = True
                    break
                    
            elif region_type == 'polygon' and len(points) >= 3:
                # å¤šè¾¹å½¢åŒºåŸŸ
                polygon = []
                for point in points:
                    converted = convert_point(point, region_coord_type)
                    if converted is not None:
                        polygon.append(tuple(converted))
                
                if len(polygon) < 3:
                    continue
                
                # åˆ¤æ–­ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨å¤šè¾¹å½¢å†…
                if point_in_polygon((center_x, center_y), polygon):
                    in_any_region = True
                    break
        
        if in_any_region:
            filtered_objects.append(obj)
    
    return filtered_objects


class InferenceRequest:
    """æ¨ç†è¯·æ±‚å¯¹è±¡"""
    
    def __init__(self, request_id, image, request_data):
        self.request_id = request_id
        self.image = image
        self.request_data = request_data
        self.result = None
        self.error = None
        self.event = threading.Event()
        self.submit_time = time.time()


class ObjectTracker:
    """ç®€å•çš„ç›®æ ‡è·Ÿè¸ªå™¨ï¼ˆåŸºäºIOUåŒ¹é…ï¼‰"""
    
    def __init__(self, track_id, bbox, confidence, class_name):
        self.track_id = track_id
        self.bbox = bbox
        self.confidence = confidence
        self.class_name = class_name
        self.center_history = []
        self.last_update = time.time()
        self.crossed_lines = set()
        
        center = self.get_center(bbox)
        self.center_history.append(center)
    
    @staticmethod
    def get_center(bbox):
        """è·å–è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹"""
        x1, y1, x2, y2 = bbox
        return ((x1 + x2) / 2, (y1 + y2) / 2)
    
    def update(self, bbox, confidence):
        """æ›´æ–°è·Ÿè¸ªå™¨"""
        self.bbox = bbox
        self.confidence = confidence
        self.last_update = time.time()
        
        center = self.get_center(bbox)
        self.center_history.append(center)
        
        if len(self.center_history) > 10:
            self.center_history.pop(0)
    
    def get_trajectory(self):
        """è·å–è½¨è¿¹ï¼ˆæœ€è¿‘ä¸¤ä¸ªç‚¹ï¼‰"""
        if len(self.center_history) >= 2:
            return self.center_history[-2], self.center_history[-1]
        return None
    
    @staticmethod
    def iou(bbox1, bbox2):
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IOU"""
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        if x2_i < x1_i or y2_i < y1_i:
            return 0.0
        
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0


class TrackerManager:
    """ç›®æ ‡è·Ÿè¸ªç®¡ç†å™¨"""
    
    def __init__(self, iou_threshold=0.3, max_age=30):
        self.trackers = {}
        self.next_id = 1
        self.iou_threshold = iou_threshold
        self.max_age = max_age
        self.task_accumulators = defaultdict(lambda: defaultdict(int))
        self.last_reset_time = time.time()
        self.reset_interval = 24 * 60 * 60
    
    def update(self, detections):
        """æ›´æ–°è·Ÿè¸ªå™¨"""
        current_time = time.time()
        
        matched_trackers = set()
        matched_detections = set()
        
        for det_idx, detection in enumerate(detections):
            best_iou = 0
            best_tracker_id = None
            
            for track_id, tracker in self.trackers.items():
                iou = ObjectTracker.iou(detection['bbox'], tracker.bbox)
                if iou > self.iou_threshold and iou > best_iou:
                    best_iou = iou
                    best_tracker_id = track_id
            
            if best_tracker_id is not None:
                self.trackers[best_tracker_id].update(detection['bbox'], detection['confidence'])
                matched_trackers.add(best_tracker_id)
                matched_detections.add(det_idx)
        
        for det_idx, detection in enumerate(detections):
            if det_idx not in matched_detections:
                tracker = ObjectTracker(
                    self.next_id,
                    detection['bbox'],
                    detection['confidence'],
                    detection['class']
                )
                self.trackers[self.next_id] = tracker
                self.next_id += 1
        
        to_remove = []
        for track_id, tracker in self.trackers.items():
            if current_time - tracker.last_update > self.max_age:
                to_remove.append(track_id)
        
        for track_id in to_remove:
            del self.trackers[track_id]
        
        return list(self.trackers.values())
    
    def check_and_reset_accumulators(self):
        """æ£€æŸ¥å¹¶é‡ç½®ç´¯åŠ å™¨ï¼ˆæ¯å¤©è‡ªåŠ¨æ¸…é›¶ï¼‰"""
        current_time = time.time()
        if current_time - self.last_reset_time >= self.reset_interval:
            print(f"  ğŸ”„ ç´¯åŠ å™¨è‡ªåŠ¨æ¸…é›¶ï¼ˆ24å°æ—¶é—´éš”ï¼‰")
            for task_id in self.task_accumulators:
                for region_id in self.task_accumulators[task_id]:
                    old_count = self.task_accumulators[task_id][region_id]
                    self.task_accumulators[task_id][region_id] = 0
                    print(f"    {task_id}.{region_id}: {old_count} -> 0")
            self.last_reset_time = current_time
    
    def check_line_crossing(self, task_id, regions, image_size=None):
        """æ£€æŸ¥è·Ÿè¸ªç›®æ ‡æ˜¯å¦è·¨è¶Šçº¿æ®µ"""
        self.check_and_reset_accumulators()
        
        crossing_results = {}
        
        for region in regions:
            if not region.get('enabled', True):
                continue
            
            if region.get('type') != 'line':
                continue
            
            region_id = region.get('id')
            points = region.get('points', [])
            direction = region.get('properties', {}).get('direction', 'both')
            
            if len(points) < 2:
                continue
            
            p1 = tuple(points[0])
            p2 = tuple(points[1])
            
            if image_size and any(0 <= coord <= 1 for point in points for coord in point):
                width, height = image_size
                p1 = (int(points[0][0] * width), int(points[0][1] * height))
                p2 = (int(points[1][0] * width), int(points[1][1] * height))
            else:
                p1 = tuple(map(int, points[0]))
                p2 = tuple(map(int, points[1]))
            
            for tracker in self.trackers.values():
                trajectory = tracker.get_trajectory()
                if trajectory is None:
                    continue
                
                start_point, end_point = trajectory
                
                if self._segments_intersect(start_point, end_point, p1, p2):
                    cross_direction = self._get_cross_direction(start_point, end_point, p1, p2)
                    
                    should_count = False
                    if direction == 'both':
                        should_count = True
                    elif direction == 'in' and cross_direction == 'in':
                        should_count = True
                    elif direction == 'out' and cross_direction == 'out':
                        should_count = True
                    
                    if should_count:
                        current_time = time.time()
                        last_cross_time = getattr(tracker, f'last_cross_{region_id}', 0)
                        if current_time - last_cross_time > 0.5:
                            self.task_accumulators[task_id][region_id] += 1
                            print(f"    [ç»Šçº¿ç»Ÿè®¡] ID:{tracker.track_id} è·¨çº¿ {region_id} ({cross_direction}) -> ç´¯åŠ : {self.task_accumulators[task_id][region_id]}")
                            
                            setattr(tracker, f'last_cross_{region_id}', current_time)
                            
                            cross_key = f"{task_id}_{region_id}_{tracker.track_id}"
                            if cross_key not in tracker.crossed_lines:
                                tracker.crossed_lines.add(cross_key)
            
            crossing_results[region_id] = {
                'region_name': region.get('name', region_id),
                'count': self.task_accumulators[task_id][region_id],
                'direction': direction
            }
        
        return crossing_results
    
    @staticmethod
    def _segments_intersect(p1, p2, p3, p4):
        """åˆ¤æ–­ä¸¤æ¡çº¿æ®µæ˜¯å¦ç›¸äº¤"""
        def ccw(A, B, C):
            return (C[1] - A[1]) * (B[0] - A[0]) > (B[1] - A[1]) * (C[0] - A[0])
        
        return ccw(p1, p3, p4) != ccw(p2, p3, p4) and ccw(p1, p2, p3) != ccw(p1, p2, p4)
    
    @staticmethod
    def _get_cross_direction(start, end, line_p1, line_p2):
        """åˆ¤æ–­è·¨è¶Šæ–¹å‘"""
        def cross_product(o, a, b):
            return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0])
        
        cp_start = cross_product(line_p1, line_p2, start)
        cp_end = cross_product(line_p1, line_p2, end)
        
        if cp_start > 0 and cp_end < 0:
            return 'in'
        elif cp_start < 0 and cp_end > 0:
            return 'out'
        
        return 'unknown'


class BatchInferenceProcessor:
    """æ‰¹å¤„ç†æ¨ç†å¤„ç†å™¨"""
    
    def __init__(self, model, batch_size=8, batch_timeout=0.1):
        self.model = model
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.request_queue = queue.Queue(maxsize=CONFIG['max_queue_size'])
        self.running = True
        self.stats_lock = threading.Lock()
        self.post_process_pool = ThreadPoolExecutor(max_workers=16, thread_name_prefix="PostProcess")
        
    def submit_request(self, image, request_data):
        """æäº¤æ¨ç†è¯·æ±‚"""
        request_id = str(uuid.uuid4())
        request = InferenceRequest(request_id, image, request_data)
        
        try:
            self.request_queue.put(request, block=True, timeout=5.0)
            INFERENCE_EVENTS[request_id] = request.event
            
            with self.stats_lock:
                BATCH_STATS['total_requests'] += 1
            
            return request_id, request
        except queue.Full:
            raise Exception("æ¨ç†é˜Ÿåˆ—å·²æ»¡ï¼Œè¯·ç¨åé‡è¯•")
    
    def process_loop(self):
        """æ‰¹å¤„ç†å¾ªç¯"""
        print("æ‰¹å¤„ç†æ¨ç†çº¿ç¨‹å·²å¯åŠ¨")
        
        while self.running:
            try:
                batch_requests = []
                deadline = time.time() + self.batch_timeout
                
                try:
                    first_request = self.request_queue.get(timeout=1.0)
                    batch_requests.append(first_request)
                except queue.Empty:
                    continue
                
                while len(batch_requests) < self.batch_size and time.time() < deadline:
                    try:
                        remaining_time = deadline - time.time()
                        if remaining_time <= 0:
                            break
                        request = self.request_queue.get(timeout=remaining_time)
                        batch_requests.append(request)
                    except queue.Empty:
                        break
                
                if not batch_requests:
                    continue
                
                self._process_batch(batch_requests)
                
            except Exception as e:
                print(f"æ‰¹å¤„ç†å¾ªç¯é”™è¯¯: {str(e)}")
                import traceback
                traceback.print_exc()
    
    def _process_batch(self, batch_requests):
        """å¤„ç†ä¸€æ‰¹è¯·æ±‚"""
        batch_size = len(batch_requests)
        
        try:
            print(f"\n{'='*60}")
            print(f"å¼€å§‹æ‰¹å¤„ç†æ¨ç† [{time.strftime('%H:%M:%S')}]")
            print(f"  æ‰¹å¤§å°: {batch_size}")
            
            images = [req.image for req in batch_requests]
            
            inference_start = time.time()
            results = self.model(images)
            inference_time = (time.time() - inference_start) * 1000
            
            print(f"  âœ“ æ‰¹é‡æ¨ç†å®Œæˆ: {inference_time:.0f}ms")
            
            post_process_start = time.time()
            
            futures = []
            for idx, (request, result) in enumerate(zip(batch_requests, results)):
                future = self.post_process_pool.submit(
                    self._process_single_result_wrapper,
                    request, result, inference_time / batch_size, idx, batch_size
                )
                futures.append((future, request))
            
            for future, request in futures:
                try:
                    future.result()
                except Exception as e:
                    request.error = str(e)
                    print(f"  âš ï¸  åå¤„ç†å¤±è´¥: {str(e)}")
            
            post_process_time = (time.time() - post_process_start) * 1000
            print(f"  âœ“ å¹¶è¡Œåå¤„ç†å®Œæˆ: {post_process_time:.0f}ms")
            
            with self.stats_lock:
                BATCH_STATS['total_batches'] += 1
                BATCH_STATS['total_inference_time'] += inference_time
                BATCH_STATS['avg_batch_size'] = (
                    (BATCH_STATS['avg_batch_size'] * (BATCH_STATS['total_batches'] - 1) + batch_size) 
                    / BATCH_STATS['total_batches']
                )
                BATCH_STATS['max_batch_size'] = max(BATCH_STATS['max_batch_size'], batch_size)
            
            print(f"  æ‰¹å¤„ç†å®Œæˆ: {batch_size} ä¸ªè¯·æ±‚")
            print(f"{'='*60}")
            
        except Exception as e:
            print(f"æ‰¹å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            for request in batch_requests:
                request.error = f"æ‰¹å¤„ç†å¤±è´¥: {str(e)}"
                INFERENCE_RESULTS[request.request_id] = {
                    'result': None,
                    'error': request.error
                }
                request.event.set()
    
    def _process_single_result_wrapper(self, request, yolo_result, inference_time_per_image, idx, batch_size):
        """åå¤„ç†åŒ…è£…å™¨"""
        try:
            self._process_single_result(request, yolo_result, inference_time_per_image)
        except Exception as e:
            request.error = str(e)
            print(f"  è¯·æ±‚ {idx+1}/{batch_size} åå¤„ç†å¤±è´¥: {str(e)}")
        finally:
            INFERENCE_RESULTS[request.request_id] = {
                'result': request.result,
                'error': request.error
            }
            request.event.set()
    
    def _process_single_result(self, request, yolo_result, inference_time_per_image):
        """å¤„ç†å•ä¸ªæ¨ç†ç»“æœï¼ˆç»Šçº¿ä¸“ç”¨ç‰ˆæœ¬ï¼‰"""
        global TRACKER_MANAGER, TRACKER_LOCK, LAST_CROSSING_COUNTS, LAST_CROSSING_COUNTS_LOCK
        
        request_data = request.request_data
        image = request.image
        task_id = request_data.get('task_id', 'unknown')
        algo_config = request_data.get('algo_config')
        if not algo_config:
            algo_config = load_algo_config(request_data.get('image_url', ''))
        
        # è·å–ç®—æ³•å‚æ•°
        confidence_threshold = 0.5
        if algo_config:
            algo_params = algo_config.get('algorithm_params', {})
            confidence_threshold = algo_params.get('confidence_threshold', 0.5)
        
        # è§£ææ¨ç†ç»“æœ
        boxes = yolo_result.boxes
        objects = []
        detections = []
        
        if boxes is not None and len(boxes) > 0:
            for box in boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().tolist()
                conf = float(box.conf[0].cpu().numpy())
                cls_id = int(box.cls[0].cpu().numpy())
                
                class_name = self.model.model.names[cls_id] if hasattr(self.model.model, 'names') else str(cls_id)
                
                if conf < confidence_threshold:
                    continue
                
                obj = {
                    'class': class_name,
                    'confidence': conf,
                    'bbox': [float(x1), float(y1), float(x2), float(y2)]
                }
                objects.append(obj)
                detections.append(obj)
        
        # ã€åŒºåŸŸè¿‡æ»¤ã€‘å¦‚æœé…ç½®äº†æ£€æµ‹åŒºåŸŸï¼Œåªä¿ç•™åŒºåŸŸå†…çš„ç‰©ä½“
        original_count = len(objects)
        regions = []
        if algo_config:
            regions = algo_config.get('regions', [])
            if regions:
                image_size = (image.shape[1], image.shape[0])
                objects = filter_objects_by_region(objects, algo_config, image_size)
                detections = filter_objects_by_region(detections, algo_config, image_size)
                filtered_count = original_count - len(objects)
                if filtered_count > 0:
                    print(f"  â„¹ï¸  åŒºåŸŸè¿‡æ»¤: åŸå§‹ {original_count} ä¸ª â†’ åŒºåŸŸå†… {len(objects)} ä¸ª (è¿‡æ»¤æ‰ {filtered_count} ä¸ª)")
        
        # æ„å»ºç»“æœ
        result_data = {
            'objects': objects,
            'total_count': len(objects),
        }
        
        # è·Ÿè¸ªå’Œç»Šçº¿æ£€æµ‹
        line_crossing_results = None
        trackers = []
        
        if TRACKER_MANAGER and detections:
            with TRACKER_LOCK:
                trackers = TRACKER_MANAGER.update(detections)
        
        if algo_config and trackers:
            regions = algo_config.get('regions', [])
            
            if regions:
                image_size = (image.shape[1], image.shape[0])
                with TRACKER_LOCK:
                    line_crossing_results = TRACKER_MANAGER.check_line_crossing(task_id, regions, image_size)
                
                if line_crossing_results:
                    # ã€ç»Šçº¿å¢é‡å‘Šè­¦ã€‘åªæœ‰å‘ç”Ÿæ–°ç©¿è¶Šæ—¶æ‰è¿”å›å‘Šè­¦
                    total_crossed = sum(info['count'] for info in line_crossing_results.values())
                    
                    with LAST_CROSSING_COUNTS_LOCK:
                        last_count = LAST_CROSSING_COUNTS.get(task_id, 0)
                        
                        if total_crossed > last_count:
                            # æœ‰æ–°ç©¿è¶Š â†’ è¿”å›å®Œæ•´ç»“æœï¼ˆè§¦å‘å‘Šè­¦ï¼‰
                            new_crossings = total_crossed - last_count
                            result_data['person_count'] = new_crossings
                            result_data['line_crossing'] = line_crossing_results
                            LAST_CROSSING_COUNTS[task_id] = total_crossed
                            print(f"  âœ… æ£€æµ‹åˆ°æ–°ç©¿è¶Š: {last_count} â†’ {total_crossed} (+{new_crossings})ï¼Œä¸Šä¼ å‘Šè­¦")
                            print(f"     è¿”å›: total_count={result_data['total_count']}, person_count={new_crossings}, objects={len(result_data['objects'])}")
                        else:
                            # æ— æ–°ç©¿è¶Š â†’ è¿”å›ç©ºç»“æœï¼ˆä¸è§¦å‘å‘Šè­¦ï¼‰
                            result_data['total_count'] = 0
                            result_data['objects'] = []
                            print(f"  â„¹ï¸  æ— æ–°ç©¿è¶Šï¼ˆç´¯è®¡={total_crossed}ï¼‰ï¼Œè¿”å›ç©ºç»“æœï¼ˆä¸ä¸Šä¼ å‘Šè­¦ï¼‰")
                            print(f"     è¿”å›: total_count=0, objects=[], æ— person_count")
                else:
                    # æ— æœ‰æ•ˆè·¨çº¿æ£€æµ‹ç»“æœ â†’ è¿”å›ç©ºç»“æœ
                    result_data['total_count'] = 0
                    result_data['objects'] = []
                    print(f"  â„¹ï¸  ç»Šçº¿äººæ•°ç»Ÿè®¡ä½†æ— æœ‰æ•ˆè·¨çº¿ç»“æœï¼Œè¿”å›ç©ºç»“æœ")
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦ï¼ˆæ³¨æ„ï¼šæ— æ–°ç©¿è¶Šæ—¶ objects ä¼šè¢«æ¸…ç©ºï¼‰
        avg_confidence = 0.0
        if result_data.get('objects') and len(result_data['objects']) > 0:
            avg_confidence = sum(obj['confidence'] for obj in result_data['objects']) / len(result_data['objects'])
        
        # è®¡ç®—æ€»å¤„ç†æ—¶é—´ï¼ˆä»æäº¤åˆ°ç°åœ¨ï¼‰
        total_time = (time.time() - request.submit_time) * 1000
        
        # æ›´æ–°æœ€è¿‘ä¸€æ¬¡æ—¶é—´ç»Ÿè®¡
        global BATCH_STATS
        BATCH_STATS['last_inference_time'] = inference_time_per_image
        BATCH_STATS['last_total_time'] = total_time
        
        # ä¿å­˜ç»“æœ
        request.result = {
            'success': True,
            'result': result_data,
            'confidence': avg_confidence,
            'inference_time_ms': round(inference_time_per_image, 2),  # æ¨¡å‹æ¨ç†æ—¶é—´
            'total_time_ms': round(total_time, 2),  # å…¨éƒ¨å¤„ç†æ—¶é—´ï¼ˆåŒ…å«ç­‰å¾…ã€æ¨ç†ã€åå¤„ç†ï¼‰
            'image_url': request_data.get('image_url', ''),  # è¯·æ±‚çš„å›¾ç‰‡URL
            'task_id': task_id  # ä»»åŠ¡ID
        }
    
    def stop(self):
        """åœæ­¢å¤„ç†å™¨"""
        self.running = False


def load_algo_config(image_url):
    """åŠ è½½ç®—æ³•é…ç½®æ–‡ä»¶"""
    try:
        from urllib.parse import urlparse, unquote
        parsed = urlparse(image_url)
        
        path_parts = parsed.path.rsplit('/', 1)
        if len(path_parts) == 2:
            config_url = f"{parsed.scheme}://{parsed.netloc}{path_parts[0]}/algo_config.json"
            
            print(f"  ğŸ” å°è¯•åŠ è½½é…ç½®æ–‡ä»¶: {config_url}")
            
            response = requests.get(config_url, timeout=5)
            if response.status_code == 200:
                config = response.json()
                print(f"  âœ“ æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶")
                print(f"  ğŸ“‹ é…ç½®å†…å®¹: task_id={config.get('task_id')}, regions={len(config.get('regions', []))}")
                
                try:
                    config_dir = Path("/cv_space/predict/configs")
                    config_dir.mkdir(parents=True, exist_ok=True)
                    
                    task_id = config.get('task_id', 'unknown')
                    general_config_path = config_dir / f"{task_id}_algo_config.json"
                    
                    should_save = True
                    if general_config_path.exists():
                        try:
                            with open(general_config_path, 'r', encoding='utf-8') as f:
                                existing_config = json.load(f)
                                if existing_config == config:
                                    should_save = False
                                    print(f"  â„¹ï¸  é…ç½®æ–‡ä»¶æœªæ”¹å˜ï¼Œè·³è¿‡ä¿å­˜")
                        except:
                            pass
                    
                    if should_save:
                        with open(general_config_path, 'w', encoding='utf-8') as f:
                            json.dump(config, f, ensure_ascii=False, indent=2)
                        print(f"  ğŸ’¾ é…ç½®æ–‡ä»¶å·²ä¿å­˜: {general_config_path}")
                    
                except Exception as save_error:
                    print(f"  âš ï¸  ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {str(save_error)}")
                
                return config
            else:
                print(f"  âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {config_url}")
        else:
            print(f"  âŒ æ— æ³•ä»URLè§£æè·¯å¾„: {image_url}")
        
    except Exception as e:
        print(f"  âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    print(f"  âš ï¸  æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œç»Šçº¿å°†ä¸ä¼šå·¥ä½œ")
    return None


class YOLOInferenceHandler(BaseHTTPRequestHandler):
    """HTTPæ¨ç†è¯·æ±‚å¤„ç†å™¨"""
    
    def log_message(self, format, *args):
        """è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼"""
        print(f"[{self.log_date_time_string()}] {format % args}")
    
    def do_POST(self):
        """å¤„ç†POSTè¯·æ±‚"""
        if self.path == '/infer':
            self.handle_inference()
        elif self.path == '/health':
            self.handle_health()
        elif self.path == '/reset_stats':
            self.handle_reset_stats()
        else:
            self.send_error(404, "Not Found")
    
    def do_GET(self):
        """å¤„ç†GETè¯·æ±‚"""
        if self.path == '/health':
            self.handle_health()
        elif self.path == '/':
            self.handle_index()
        elif self.path == '/stats':
            self.handle_stats()
        else:
            self.send_error(404, "Not Found")
    
    def handle_index(self):
        """é¦–é¡µ"""
        self.send_response(200)
        self.send_header('Content-type', 'text/html; charset=utf-8')
        self.end_headers()
        
        batching_status = "å¯ç”¨" if CONFIG['enable_batching'] else "ç¦ç”¨"
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>{CONFIG['name']}</title>
            <meta charset="utf-8">
            <style>
                body {{
                    font-family: Arial, sans-serif;
                    max-width: 900px;
                    margin: 50px auto;
                    padding: 20px;
                    background: #f5f5f5;
                }}
                .container {{
                    background: white;
                    padding: 30px;
                    border-radius: 10px;
                    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                }}
                h1 {{
                    color: #333;
                    border-bottom: 3px solid #2196F3;
                    padding-bottom: 10px;
                }}
                .info-grid {{
                    display: grid;
                    grid-template-columns: repeat(2, 1fr);
                    gap: 15px;
                    margin: 20px 0;
                }}
                .info-item {{
                    padding: 15px;
                    background: #f9f9f9;
                    border-radius: 5px;
                    border-left: 4px solid #2196F3;
                }}
                .info-item strong {{
                    color: #666;
                    display: block;
                    margin-bottom: 5px;
                    font-size: 14px;
                }}
                .info-item span {{
                    color: #333;
                    font-size: 18px;
                    font-weight: bold;
                }}
                .stats-section {{
                    margin: 30px 0;
                    padding: 20px;
                    background: #e3f2fd;
                    border-radius: 5px;
                }}
                .stats-section h2 {{
                    margin-top: 0;
                    color: #1565c0;
                }}
                .stat-value {{
                    font-size: 32px;
                    font-weight: bold;
                    color: #0d47a1;
                    margin: 10px 0;
                }}
                .btn {{
                    background: #f44336;
                    color: white;
                    border: none;
                    padding: 12px 30px;
                    font-size: 16px;
                    border-radius: 5px;
                    cursor: pointer;
                    transition: background 0.3s;
                }}
                .btn:hover {{
                    background: #d32f2f;
                }}
                .btn:active {{
                    transform: scale(0.98);
                }}
                .message {{
                    padding: 15px;
                    margin: 15px 0;
                    border-radius: 5px;
                    display: none;
                }}
                .message.success {{
                    background: #4CAF50;
                    color: white;
                }}
                .endpoints {{
                    margin: 20px 0;
                    padding: 15px;
                    background: #fff3cd;
                    border-radius: 5px;
                    border-left: 4px solid #ffc107;
                }}
                .endpoints code {{
                    background: #fff;
                    padding: 2px 6px;
                    border-radius: 3px;
                    font-family: monospace;
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>ğŸš¶ {CONFIG['name']}</h1>
                
                <div class="info-grid">
                    <div class="info-item">
                        <strong>æœåŠ¡ID</strong>
                        <span>{CONFIG['service_id']}</span>
                    </div>
                    <div class="info-item">
                        <strong>ç‰ˆæœ¬</strong>
                        <span>{CONFIG['version']}</span>
                    </div>
                    <div class="info-item">
                        <strong>æ”¯æŒä»»åŠ¡ç±»å‹</strong>
                        <span>{', '.join(CONFIG['task_types'])}</span>
                    </div>
                    <div class="info-item">
                        <strong>æ‰¹å¤„ç†æ¨¡å¼</strong>
                        <span>{batching_status}</span>
                    </div>
                </div>

                <div class="stats-section">
                    <h2>ğŸ“Š å®æ—¶ç»Ÿè®¡</h2>
                    <div class="info-item">
                        <strong>ç´¯ç§¯æ¨ç†æ¬¡æ•°</strong>
                        <div class="stat-value" id="total-requests">åŠ è½½ä¸­...</div>
                    </div>
                    <div class="info-item" style="margin-top: 15px;">
                        <strong>å¹³å‡æ¨ç†æ—¶é—´</strong>
                        <div class="stat-value" id="avg-time">åŠ è½½ä¸­...</div>
                    </div>
                    <div class="info-item" style="margin-top: 15px;">
                        <strong>æ€»æ‰¹æ¬¡æ•°</strong>
                        <div class="stat-value" id="total-batches">åŠ è½½ä¸­...</div>
                    </div>
                    <button class="btn" onclick="resetStats()">ğŸ”„ æ¸…é›¶ç»Ÿè®¡æ•°æ®</button>
                    <div id="message" class="message"></div>
                </div>

                <div class="endpoints">
                    <h3>ğŸ”Œ API ç«¯ç‚¹</h3>
                    <p><strong>æ¨ç†:</strong> <code>POST /infer</code></p>
                    <p><strong>å¥åº·æ£€æŸ¥:</strong> <code>GET /health</code></p>
                    <p><strong>ç»Ÿè®¡ä¿¡æ¯:</strong> <code>GET /stats</code></p>
                    <p><strong>æ¸…é›¶ç»Ÿè®¡:</strong> <code>POST /reset_stats</code></p>
                </div>
            </div>

            <script>
                // åŠ è½½ç»Ÿè®¡æ•°æ®
                function loadStats() {{
                    fetch('/stats')
                        .then(res => res.json())
                        .then(data => {{
                            const stats = data.statistics || {{}};
                            const totalRequests = stats.total_requests || 0;
                            const totalBatches = stats.total_batches || 0;
                            
                            // è®¡ç®—å¹³å‡æ¨ç†æ—¶é—´
                            let avgTime = 0;
                            if (totalRequests > 0 && stats.total_inference_time) {{
                                avgTime = stats.total_inference_time / totalRequests;
                            }}
                            
                            document.getElementById('total-requests').textContent = totalRequests.toLocaleString();
                            document.getElementById('avg-time').textContent = avgTime.toFixed(2) + ' ms';
                            document.getElementById('total-batches').textContent = totalBatches.toLocaleString();
                        }})
                        .catch(err => {{
                            console.error('åŠ è½½ç»Ÿè®¡å¤±è´¥:', err);
                            document.getElementById('total-requests').textContent = 'åŠ è½½å¤±è´¥';
                            document.getElementById('avg-time').textContent = 'åŠ è½½å¤±è´¥';
                            document.getElementById('total-batches').textContent = 'åŠ è½½å¤±è´¥';
                        }});
                }}

                // æ¸…é›¶ç»Ÿè®¡æ•°æ®
                function resetStats() {{
                    if (!confirm('ç¡®å®šè¦æ¸…é›¶æ‰€æœ‰ç»Ÿè®¡æ•°æ®å—ï¼Ÿ')) {{
                        return;
                    }}
                    
                    fetch('/reset_stats', {{ method: 'POST' }})
                        .then(res => res.json())
                        .then(data => {{
                            if (data.success) {{
                                showMessage('ç»Ÿè®¡æ•°æ®å·²æ¸…é›¶', 'success');
                                loadStats();
                            }}
                        }})
                        .catch(err => {{
                            console.error('æ¸…é›¶å¤±è´¥:', err);
                            alert('æ¸…é›¶å¤±è´¥: ' + err);
                        }});
                }}

                // æ˜¾ç¤ºæ¶ˆæ¯
                function showMessage(msg, type) {{
                    const msgDiv = document.getElementById('message');
                    msgDiv.textContent = msg;
                    msgDiv.className = 'message ' + type;
                    msgDiv.style.display = 'block';
                    setTimeout(() => {{
                        msgDiv.style.display = 'none';
                    }}, 3000);
                }}

                // åˆå§‹åŠ è½½å’Œå®šæ—¶åˆ·æ–°
                loadStats();
                setInterval(loadStats, 3000);  // æ¯3ç§’åˆ·æ–°ä¸€æ¬¡
            </script>
        </body>
        </html>
        """
        self.wfile.write(html.encode('utf-8'))
    
    def handle_health(self):
        """å¥åº·æ£€æŸ¥"""
        self.send_response(200)
        self.send_header('Content-type', 'application/json')
        self.end_headers()
        
        response = {
            'status': 'healthy',
            'service_id': CONFIG['service_id'],
            'version': CONFIG['version'],
            'model_loaded': MODEL is not None,
            'batching_enabled': CONFIG['enable_batching']
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def handle_stats(self):
        """æ€§èƒ½ç»Ÿè®¡"""
        self.send_response(200)
        self.send_header('Content-type', 'application/json')
        self.end_headers()
        
        global BATCH_STATS, BATCH_PROCESSOR
        
        stats = {
            'batching_enabled': CONFIG['enable_batching'],
            'batch_config': {
                'batch_size': CONFIG['batch_size'],
                'batch_timeout': CONFIG['batch_timeout'],
                'max_queue_size': CONFIG['max_queue_size']
            },
            'statistics': dict(BATCH_STATS) if CONFIG['enable_batching'] else {},
            'queue_size': BATCH_PROCESSOR.request_queue.qsize() if BATCH_PROCESSOR else 0
        }
        
        self.wfile.write(json.dumps(stats, indent=2).encode('utf-8'))
    
    def handle_reset_stats(self):
        """æ¸…é›¶ç»Ÿè®¡æ•°æ®"""
        global BATCH_STATS
        
        BATCH_STATS['total_requests'] = 0
        BATCH_STATS['total_batches'] = 0
        BATCH_STATS['total_inference_time'] = 0.0
        BATCH_STATS['avg_batch_size'] = 0.0
        BATCH_STATS['max_batch_size'] = 0
        BATCH_STATS['last_inference_time'] = 0.0
        BATCH_STATS['last_total_time'] = 0.0
        
        print(f"\n[{time.strftime('%H:%M:%S')}] ç»Ÿè®¡æ•°æ®å·²æ¸…é›¶")
        
        self.send_response(200)
        self.send_header('Content-type', 'application/json')
        self.end_headers()
        
        response = {
            'success': True,
            'message': 'ç»Ÿè®¡æ•°æ®å·²æ¸…é›¶'
        }
        self.wfile.write(json.dumps(response).encode('utf-8'))
    
    def handle_inference(self):
        """å¤„ç†æ¨ç†è¯·æ±‚"""
        global MODEL, TRACKER_MANAGER, BATCH_PROCESSOR
        
        start_time = time.time()
        image_url = ''
        task_id = 'unknown'
        
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            request_data = json.loads(post_data.decode('utf-8'))
            
            image_url = request_data.get('image_url', '')
            task_id = request_data.get('task_id', 'unknown')
            
            if not image_url:
                raise ValueError("ç¼ºå°‘image_urlå‚æ•°")
            
            # åŠ è½½ç®—æ³•é…ç½®æ–‡ä»¶
            algo_config = load_algo_config(image_url)
            if not algo_config:
                raise ValueError("ç»Šçº¿äººæ•°ç»Ÿè®¡å¿…é¡»æœ‰é…ç½®æ–‡ä»¶")
            
            # ä¸‹è½½å›¾ç‰‡
            temp_image_path = f'/tmp/inference_{int(time.time()*1000)}.jpg'
            try:
                urllib.request.urlretrieve(image_url, temp_image_path)
            except Exception as e:
                raise ValueError(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {str(e)}")
            
            # è¯»å–å›¾ç‰‡
            image = cv2.imread(temp_image_path)
            if image is None:
                raise ValueError("æ— æ³•è¯»å–å›¾ç‰‡")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_image_path)
            except:
                pass
            
            print(f"\n" + "="*60)
            print(f"æ”¶åˆ°æ¨ç†è¯·æ±‚ [{time.strftime('%H:%M:%S')}]")
            print(f"  ä»»åŠ¡ID: {task_id}")
            print(f"  ä»»åŠ¡ç±»å‹: ç»Šçº¿äººæ•°ç»Ÿè®¡")
            print(f"-"*60)
            
            # æ‰¹å¤„ç†æ¨ç†
            if CONFIG['enable_batching'] and BATCH_PROCESSOR:
                request_data['algo_config'] = algo_config
                request_id, request_obj = BATCH_PROCESSOR.submit_request(image, request_data)
                
                if not request_obj.event.wait(timeout=30.0):
                    raise Exception("æ¨ç†è¶…æ—¶")
                
                result_info = INFERENCE_RESULTS.get(request_id)
                if not result_info:
                    raise Exception("æ¨ç†ç»“æœä¸¢å¤±")
                
                if result_info['error']:
                    raise Exception(result_info['error'])
                
                response = result_info['result']
                
                try:
                    del INFERENCE_RESULTS[request_id]
                    del INFERENCE_EVENTS[request_id]
                except:
                    pass
                
                total_time = (time.time() - start_time) * 1000
                inference_time = response.get('inference_time_ms', 0)
                print(f"  æ¨ç†å®Œæˆ: æ¨ç†æ—¶é—´ {inference_time:.0f}ms, æ€»è€—æ—¶ {total_time:.0f}ms")
                print(f"="*60)
            
            # å‘é€å“åº”
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps(response).encode('utf-8'))
            
        except Exception as e:
            print(f"  æ¨ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            total_time = (time.time() - start_time) * 1000
            
            error_response = {
                'success': False,
                'error': str(e),
                'confidence': 0.0,
                'inference_time_ms': 0,
                'total_time_ms': round(total_time, 2),
                'image_url': image_url,  # è¯·æ±‚çš„å›¾ç‰‡URL
                'task_id': task_id  # ä»»åŠ¡ID
            }
            
            self.send_response(500)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps(error_response).encode('utf-8'))


def load_model():
    """åŠ è½½YOLOæ¨¡å‹"""
    global MODEL
    
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {CONFIG['model_path']}")
    start_time = time.time()
    
    MODEL = YOLO(CONFIG['model_path'])
    
    load_time = time.time() - start_time
    print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}ç§’)")


def register_service():
    """æ³¨å†Œåˆ°EasyDarwin"""
    url = f"{CONFIG['easydarwin_url']}/api/v1/ai_analysis/register"
    
    endpoint = f"http://{CONFIG['host']}:{CONFIG['port']}/infer"
    if CONFIG['host'] == '0.0.0.0':
        import socket
        try:
            hostname = socket.gethostname()
            local_ip = socket.gethostbyname(hostname)
            endpoint = f"http://{local_ip}:{CONFIG['port']}/infer"
        except:
            pass
    
    payload = {
        'service_id': CONFIG['service_id'],
        'name': CONFIG['name'],
        'task_types': CONFIG['task_types'],
        'endpoint': endpoint,
        'version': CONFIG['version']
    }
    
    print(f"\næ­£åœ¨æ³¨å†Œåˆ° {CONFIG['easydarwin_url']}...")
    print(f"  æœåŠ¡ID: {CONFIG['service_id']}")
    print(f"  æœåŠ¡åç§°: {CONFIG['name']}")
    print(f"  ä»»åŠ¡ç±»å‹: {CONFIG['task_types']}")
    print(f"  æ¨ç†ç«¯ç‚¹: {endpoint}")
    
    try:
        response = requests.post(url, json=payload, timeout=10)
        response.raise_for_status()
        
        result = response.json()
        if result.get('ok'):
            print(f"âœ“ æ³¨å†ŒæˆåŠŸ: {result.get('service_id')}")
            return True
        else:
            print(f"âœ— æ³¨å†Œå¤±è´¥: {result}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"âœ— æ³¨å†Œå¤±è´¥: æ— æ³•è¿æ¥åˆ° {CONFIG['easydarwin_url']}")
        return False
    except Exception as e:
        print(f"âœ— æ³¨å†Œå¤±è´¥: {str(e)}")
        return False


def unregister_service():
    """æ³¨é”€æœåŠ¡"""
    url = f"{CONFIG['easydarwin_url']}/api/v1/ai_analysis/unregister/{CONFIG['service_id']}"
    
    print(f"\næ­£åœ¨æ³¨é”€æœåŠ¡: {CONFIG['service_id']}")
    
    try:
        response = requests.delete(url, timeout=10)
        response.raise_for_status()
        print("âœ“ æ³¨é”€æˆåŠŸ")
    except Exception as e:
        print(f"âœ— æ³¨é”€å¤±è´¥: {str(e)}")


def heartbeat_loop():
    """å¿ƒè·³å¾ªç¯"""
    global RUNNING
    
    url = f"{CONFIG['easydarwin_url']}/api/v1/ai_analysis/heartbeat/{CONFIG['service_id']}"
    
    print(f"å¿ƒè·³çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæ¯{CONFIG['heartbeat_interval']}ç§’ï¼‰")
    
    while RUNNING:
        time.sleep(CONFIG['heartbeat_interval'])
        
        if not RUNNING:
            break
        
        try:
            # è®¡ç®—å¹³å‡æ¨ç†æ—¶é—´
            avg_inference_time = 0.0
            if BATCH_STATS['total_requests'] > 0:
                avg_inference_time = BATCH_STATS['total_inference_time'] / BATCH_STATS['total_requests']
            
            # æºå¸¦ç»Ÿè®¡ä¿¡æ¯
            payload = {
                'total_requests': BATCH_STATS['total_requests'],
                'avg_inference_time_ms': round(avg_inference_time, 2),
                'last_inference_time_ms': round(BATCH_STATS['last_inference_time'], 2),  # æœ€è¿‘ä¸€æ¬¡æ¨ç†æ—¶é—´
                'last_total_time_ms': round(BATCH_STATS['last_total_time'], 2)  # æœ€è¿‘ä¸€æ¬¡æ€»è€—æ—¶
            }
            
            response = requests.post(url, json=payload, timeout=5)
            if response.status_code == 200:
                print(f"[{time.strftime('%H:%M:%S')}] å¿ƒè·³å‘é€æˆåŠŸ")
            else:
                print(f"[{time.strftime('%H:%M:%S')}] å¿ƒè·³å‘é€å¤±è´¥: {response.status_code}")
        except Exception as e:
            print(f"[{time.strftime('%H:%M:%S')}] å¿ƒè·³å‘é€å¤±è´¥: {str(e)}")


def signal_handler(sig, frame):
    """ä¿¡å·å¤„ç†å™¨ï¼ˆä¼˜é›…é€€å‡ºï¼‰"""
    global RUNNING
    
    print("\n\næ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    RUNNING = False


def main():
    """ä¸»å‡½æ•°"""
    global RUNNING, HEARTBEAT_THREAD, TRACKER_MANAGER, BATCH_PROCESSOR, BATCH_PROCESSOR_THREAD
    
    parser = argparse.ArgumentParser(description='YOLOv11xç»Šçº¿äººæ•°ç»Ÿè®¡ç®—æ³•æœåŠ¡')
    parser.add_argument('--service-id', default='yolo11x_line_crossing',
                        help='æœåŠ¡ID (é»˜è®¤: yolo11x_line_crossing)')
    parser.add_argument('--name', default='YOLOv11xç»Šçº¿äººæ•°ç»Ÿè®¡ç®—æ³•',
                        help='æœåŠ¡åç§°')
    parser.add_argument('--port', type=int, default=7903,
                        help='ç›‘å¬ç«¯å£ (é»˜è®¤: 7903)')
    parser.add_argument('--host', default='0.0.0.0',
                        help='ç›‘å¬åœ°å€ (é»˜è®¤: 0.0.0.0)')
    parser.add_argument('--easydarwin', default='http://localhost:5066',
                        help='EasyDarwinåœ°å€')
    parser.add_argument('--model', default='/cv_space/NWPU-Crowd/runs/exp_yolo11x3/weights/best.pt',
                        help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--gpu-id', type=str, default='3',
                        help='GPUè®¾å¤‡ID (é»˜è®¤: 3, å¯è®¾ç½®å¤šä¸ªå¦‚ "0,1")')
    parser.add_argument('--no-register', action='store_true',
                        help='ä¸æ³¨å†Œåˆ°EasyDarwin')
    parser.add_argument('--batch-size', type=int, default=8,
                        help='æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 8)')
    parser.add_argument('--batch-timeout', type=float, default=0.1,
                        help='æ‰¹å¤„ç†è¶…æ—¶ï¼ˆç§’ï¼‰')
    parser.add_argument('--no-batching', action='store_true',
                        help='ç¦ç”¨æ‰¹å¤„ç†')
    
    args = parser.parse_args()
    
    # è®¾ç½®GPUè®¾å¤‡
    os.environ["CUDA_VISIBLE_DEVICES"] = args.gpu_id
    print(f"è®¾ç½®GPUè®¾å¤‡: CUDA_VISIBLE_DEVICES={args.gpu_id}")
    
    # æ›´æ–°é…ç½®
    CONFIG['service_id'] = args.service_id
    CONFIG['name'] = args.name
    CONFIG['port'] = args.port
    CONFIG['host'] = args.host
    CONFIG['easydarwin_url'] = args.easydarwin
    CONFIG['model_path'] = args.model
    CONFIG['batch_size'] = args.batch_size
    CONFIG['batch_timeout'] = args.batch_timeout
    CONFIG['enable_batching'] = not args.no_batching
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    print("=" * 60)
    print(f"  {CONFIG['name']} v{CONFIG['version']}")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    load_model()
    
    # åˆå§‹åŒ–è·Ÿè¸ªå™¨ç®¡ç†å™¨
    TRACKER_MANAGER = TrackerManager(iou_threshold=0.3, max_age=30)
    print("âœ“ è·Ÿè¸ªå™¨ç®¡ç†å™¨å·²åˆå§‹åŒ–")
    
    # åˆå§‹åŒ–æ‰¹å¤„ç†å™¨
    if CONFIG['enable_batching']:
        BATCH_PROCESSOR = BatchInferenceProcessor(
            MODEL, 
            batch_size=CONFIG['batch_size'],
            batch_timeout=CONFIG['batch_timeout']
        )
        BATCH_PROCESSOR_THREAD = threading.Thread(target=BATCH_PROCESSOR.process_loop, daemon=True)
        BATCH_PROCESSOR_THREAD.start()
        print(f"âœ“ æ‰¹å¤„ç†æ¨ç†å·²å¯åŠ¨")
    else:
        print("âš ï¸  æ‰¹å¤„ç†å·²ç¦ç”¨")
    
    # æ³¨å†Œåˆ°EasyDarwin
    registered = False
    if not args.no_register:
        registered = register_service()
        
        if registered:
            HEARTBEAT_THREAD = threading.Thread(target=heartbeat_loop, daemon=True)
            HEARTBEAT_THREAD.start()
    else:
        print("\nâš  è·³è¿‡æ³¨å†Œåˆ°EasyDarwin")
    
    # å¯åŠ¨HTTPæœåŠ¡å™¨
    server_address = (CONFIG['host'], CONFIG['port'])
    httpd = ThreadingHTTPServer(server_address, YOLOInferenceHandler)
    print(f"âœ“ ä½¿ç”¨å¤šçº¿ç¨‹HTTPæœåŠ¡å™¨")
    
    print(f"\nç»Šçº¿äººæ•°ç»Ÿè®¡ç®—æ³•æœåŠ¡å·²å¯åŠ¨")
    print(f"  æœåŠ¡ID: {CONFIG['service_id']}")
    print(f"  æœåŠ¡åç§°: {CONFIG['name']}")
    print(f"  ç›‘å¬åœ°å€: {CONFIG['host']}:{CONFIG['port']}")
    print(f"  æ¨ç†ç«¯ç‚¹: http://{CONFIG['host']}:{CONFIG['port']}/infer")
    print(f"\nç­‰å¾…æ¨ç†è¯·æ±‚... (æŒ‰Ctrl+Cé€€å‡º)")
    print("=" * 60)
    
    # è¿è¡ŒæœåŠ¡å™¨
    try:
        while RUNNING:
            httpd.handle_request()
    except KeyboardInterrupt:
        pass
    finally:
        if registered:
            unregister_service()
        
        print("\næœåŠ¡å·²å…³é—­")
        sys.exit(0)


if __name__ == '__main__':
    main()

