# Web 管理界面使用说明

## 🎯 功能概览

Web管理界面提供了一个简单友好的界面来管理和监控算法服务，无需命令行操作。

### 核心功能
- ✅ **启动/停止服务** - 一键启动或停止算法服务
- ✅ **GPU监控** - 实时查看GPU显存、利用率、温度、功率
- ✅ **配置管理** - 界面配置GPU设备、端口、批处理参数
- ✅ **状态监控** - 实时显示服务运行状态和进程ID
- ✅ **日志查看** - 查看最近的系统日志

---

## 🚀 快速开始

### 1. 安装依赖

```bash
cd /cv_space/predict
pip install -r requirements_manager.txt
```

依赖包括：
- Flask - Web框架
- flask-cors - 跨域支持
- psutil - 进程管理
- requests - HTTP请求

### 2. 启动管理界面

```bash
./start_manager.sh
```

或者：

```bash
python3 algorithm_manager.py
```

### 3. 访问界面

打开浏览器访问：
- **http://localhost:8500**
- **http://<服务器IP>:8500**

---

## 📱 界面使用说明

### 主界面布局

```
┌─────────────────────────────────────────────────┐
│  🎯 算法服务管理器                                 │
│  管理和监控 YOLOv11x 人头检测算法服务                │
└─────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────┐
│  💻 GPU 状态监控                        🔄 刷新    │
├─────────────────────────────────────────────────┤
│  🎮 NVIDIA GeForce RTX 3090          GPU 0      │
│  ████████░░░░░░░░░░ 45.2%                       │
│  显存使用: 10800 / 24000 MB                     │
│  GPU 利用率: 78%    温度: 65°C    功率: 250W     │
└─────────────────────────────────────────────────┘

┌────────────────────┐  ┌────────────────────┐
│ 🔴 实时检测服务      │  │ 🟢 绊线统计服务      │
│ [运行中]            │  │ [已停止]            │
├────────────────────┤  ├────────────────────┤
│ GPU设备: [3__]     │  │ GPU设备: [3__]     │
│ 端口: [8501]       │  │ 端口: [8502]       │
│ 批处理: [8__]      │  │ 批处理: [8__]      │
│ [▶️ 启动] [⏹️ 停止] │  │ [▶️ 启动] [⏹️ 停止] │
└────────────────────┘  └────────────────────┘

┌─────────────────────────────────────────────────┐
│  📋 系统日志                            🔄 刷新    │
├─────────────────────────────────────────────────┤
│  [06:54:41] 收到推理请求                         │
│  批量推理完成: 27ms                              │
│  推理完成: 总耗时 60ms                           │
└─────────────────────────────────────────────────┘
```

---

## 🎮 功能详解

### 1. GPU状态监控

**显示内容：**
- GPU ID 和名称
- 显存使用量和百分比（进度条显示）
- GPU利用率
- 温度
- 功率消耗

**颜色说明：**
- 🟢 绿色 (0-60%) - 正常
- 🟡 橙色 (60-80%) - 警告
- 🔴 红色 (80-100%) - 危险

**更新频率：**
- 自动刷新：每3秒
- 手动刷新：点击"🔄 刷新"按钮

---

### 2. 实时检测服务管理

**服务信息：**
- 任务类型：人数统计、客流分析、人头检测
- 端口：8501（默认）
- GPU设备：可配置
- 进程ID：运行时显示

**可配置参数：**
- **GPU 设备 ID**: 指定使用哪个GPU（例如: 0, 1, 或 "0,1"）
- **端口**: HTTP服务监听端口
- **批处理大小**: 批量推理时的批大小（越大越快，但需要更多显存）

**操作按钮：**
- ▶️ **启动服务**: 使用当前配置启动服务
- ⏹️ **停止服务**: 停止正在运行的服务

---

### 3. 绊线统计服务管理

**服务信息：**
- 任务类型：绊线人数统计
- 端口：8502（默认）
- GPU设备：可配置
- 进程ID：运行时显示

**可配置参数：**
- **GPU 设备 ID**: 指定使用哪个GPU
- **端口**: HTTP服务监听端口
- **批处理大小**: 批量推理时的批大小

**操作按钮：**
- ▶️ **启动服务**: 使用当前配置启动服务
- ⏹️ **停止服务**: 停止正在运行的服务

---

### 4. 系统日志查看

**显示内容：**
- 最近100条日志
- 自动滚动到最新日志
- 包含推理请求、性能统计、错误信息等

**更新方式：**
- 手动刷新：点击"🔄 刷新"按钮

---

## 📋 使用场景

### 场景1：启动两个服务（不同GPU）

1. 在"实时检测服务"卡片中：
   - GPU设备改为 `0`
   - 端口保持 `8501`
   - 点击"▶️ 启动服务"

2. 在"绊线统计服务"卡片中：
   - GPU设备改为 `1`
   - 端口保持 `8502`
   - 点击"▶️ 启动服务"

3. 查看GPU监控区域，确认两个GPU都在使用

---

### 场景2：调整批处理大小优化性能

1. 如果GPU显存充足（<50%使用率）：
   - 将批处理大小从 `8` 改为 `16`
   - 停止服务
   - 重新启动服务

2. 如果GPU显存不足（>80%使用率）：
   - 将批处理大小从 `8` 改为 `4`
   - 停止服务
   - 重新启动服务

---

### 场景3：切换GPU设备

1. 停止当前运行的服务
2. 在GPU设备输入框中输入新的GPU ID（例如 `2`）
3. 重新启动服务
4. 在GPU监控区域确认新GPU正在使用

---

### 场景4：故障排查

1. 查看"系统日志"区域，查找错误信息
2. 点击"🔄 刷新"获取最新日志
3. 如果服务启动失败，检查：
   - GPU ID是否有效
   - 端口是否被占用
   - GPU显存是否充足

---

## ⚙️ 配置参数说明

### GPU 设备 ID
- **单GPU**: `0`, `1`, `2`, `3`
- **多GPU**: `"0,1"`, `"2,3"`
- **默认**: `3`

### 端口
- **实时检测**: `8501` (默认)
- **绊线统计**: `8502` (默认)
- 范围: 1024-65535

### 批处理大小
- **推荐值**: `8`
- **高显存**: `16` 或 `32`
- **低显存**: `4` 或 `2`
- 影响: 越大越快，但需要更多显存

---

## 🔧 高级功能

### 1. 修改EasyDarwin地址
如需修改EasyDarwin地址，编辑 `algorithm_manager.py`：

```python
# 找到这一行
'--easydarwin', 'http://10.1.6.230:5066'

# 修改为你的地址
'--easydarwin', 'http://your-host:5066'
```

### 2. 修改模型路径
如需使用不同的模型，在启动命令中添加 `--model` 参数：

编辑 `algorithm_manager.py` 中的 `cmd` 列表，添加：
```python
'--model', '/path/to/your/model.pt'
```

---

## 🌐 API 接口

管理界面也提供了REST API，可以通过编程方式控制：

### 获取GPU信息
```bash
curl http://localhost:8500/api/gpu-info
```

### 获取服务状态
```bash
curl http://localhost:8500/api/services
```

### 启动服务
```bash
curl -X POST http://localhost:8500/api/start-service \
  -H "Content-Type: application/json" \
  -d '{"service": "realtime", "gpu_id": "0", "port": 8501, "batch_size": 8}'
```

### 停止服务
```bash
curl -X POST http://localhost:8500/api/stop-service \
  -H "Content-Type: application/json" \
  -d '{"service": "realtime"}'
```

### 获取日志
```bash
curl http://localhost:8500/api/logs
```

---

## ⚠️ 注意事项

### 1. 端口冲突
- 管理界面占用端口 **8500**
- 实时检测服务占用端口 **8501**（默认）
- 绊线统计服务占用端口 **8502**（默认）
- 确保这些端口未被占用

### 2. 权限要求
- 需要有启动进程的权限
- 需要有读取日志文件的权限
- 需要有访问nvidia-smi的权限

### 3. 服务独立性
- 通过管理界面启动的服务会在后台运行
- 关闭管理界面不会停止已启动的算法服务
- 需要手动点击"停止"按钮来停止服务

### 4. GPU监控限制
- 需要安装nvidia-smi工具
- 只能监控NVIDIA GPU
- 如果没有GPU或nvidia-smi，GPU监控部分会显示"无法获取GPU信息"

---

## 🐛 故障排查

### 问题1: 无法访问管理界面
**解决方案：**
```bash
# 检查管理器是否启动
ps aux | grep algorithm_manager

# 检查端口是否被占用
netstat -tulpn | grep 8500

# 重新启动管理器
./start_manager.sh
```

### 问题2: GPU信息无法显示
**解决方案：**
```bash
# 检查nvidia-smi是否可用
nvidia-smi

# 如果命令不存在，安装NVIDIA驱动
# Ubuntu: sudo apt-get install nvidia-utils
```

### 问题3: 服务启动失败
**检查：**
1. GPU ID是否有效（使用nvidia-smi查看）
2. 端口是否被占用
3. 模型文件是否存在
4. 查看系统日志了解详细错误

### 问题4: 页面不刷新
**解决方案：**
- 点击"🔄 刷新"按钮手动刷新
- 页面会自动每3秒刷新一次
- 清除浏览器缓存并重新加载

---

## 📚 使用流程示例

### 完整工作流程

1. **启动管理界面**
   ```bash
   ./start_manager.sh
   ```

2. **访问Web界面**
   - 打开浏览器: http://localhost:8500

3. **查看GPU状态**
   - 查看GPU监控区域
   - 选择显存充足的GPU

4. **配置实时检测服务**
   - GPU设备: 输入 `0`
   - 端口: 保持 `8501`
   - 批处理: 保持 `8`

5. **启动实时检测服务**
   - 点击"▶️ 启动服务"
   - 等待状态变为"运行中"

6. **配置绊线统计服务**
   - GPU设备: 输入 `1`
   - 端口: 保持 `8502`
   - 批处理: 保持 `8`

7. **启动绊线统计服务**
   - 点击"▶️ 启动服务"
   - 等待状态变为"运行中"

8. **监控服务运行**
   - 查看GPU监控区域，确认显存使用正常
   - 查看系统日志，确认服务正常处理请求

9. **停止服务（如需要）**
   - 点击相应服务的"⏹️ 停止服务"
   - 等待状态变为"已停止"

---

## 🎨 界面特色

### 1. 现代化设计
- 渐变背景色
- 卡片式布局
- 柔和的阴影效果
- 响应式设计

### 2. 直观的状态显示
- **运行中** - 绿色标签
- **已停止** - 灰色标签
- GPU使用率进度条自动变色

### 3. 实时更新
- GPU信息每3秒自动刷新
- 服务状态每3秒自动刷新
- 手动刷新按钮随时可用

### 4. 友好的交互
- 按钮悬停效果
- 操作确认提示
- 成功/失败消息提示

---

## 📊 性能监控

### GPU显存监控

**进度条颜色：**
- 🟢 **绿色** (0-60%) - 正常，可以启动更多服务
- 🟡 **橙色** (60-80%) - 警告，接近满载
- 🔴 **红色** (80-100%) - 危险，可能导致OOM

**优化建议：**
- 显存 < 50%: 可以增加批处理大小
- 显存 > 80%: 建议减小批处理大小或使用其他GPU
- 显存 > 95%: 立即停止服务或切换GPU

---

## 🔐 安全建议

### 1. 生产环境部署
```bash
# 使用反向代理（nginx）
# 添加身份验证
# 限制访问IP
```

### 2. 防火墙配置
```bash
# 只允许特定IP访问
sudo ufw allow from <trusted-ip> to any port 8500
```

### 3. HTTPS配置
建议在生产环境使用HTTPS，可以通过nginx反向代理实现。

---

## 📈 性能优化建议

### 根据GPU监控调整参数

| GPU显存使用 | 批处理大小建议 | 说明 |
|-----------|-------------|------|
| < 30% | 16 或 32 | GPU空闲，可以提升批处理大小 |
| 30-60% | 8 或 16 | 正常范围 |
| 60-80% | 4 或 8 | 接近饱和，保持当前配置 |
| > 80% | 2 或 4 | 显存紧张，降低批处理大小 |

---

## 🛠️ 文件说明

```
/cv_space/predict/
├── algorithm_manager.py              # 管理器后端服务
├── start_manager.sh                  # 管理器启动脚本
├── requirements_manager.txt          # 管理器依赖
├── algorithm_service.py              # 实时检测服务
├── algorithm_service_line_crossing.py # 绊线统计服务
├── start_algorithm_service.sh        # 实时检测启动脚本
└── start_line_crossing_service.sh    # 绊线统计启动脚本
```

---

## 💡 提示和技巧

### 1. 快速重启服务
- 点击"⏹️ 停止"→ 修改配置 → 点击"▶️ 启动"

### 2. 监控性能
- 启动服务后，观察GPU显存变化
- 如果显存使用率过高，调小批处理大小

### 3. 多GPU负载均衡
- 实时检测服务（高负载）→ 使用性能最好的GPU
- 绊线统计服务（低负载）→ 使用次要GPU

### 4. 开发调试
- 查看系统日志了解详细信息
- 使用浏览器开发者工具查看网络请求
- 检查控制台是否有JavaScript错误

---

## 📞 技术支持

如有问题，请查看：
- [服务说明.md](服务说明.md) - 服务功能说明
- [GPU配置说明.md](GPU配置说明.md) - GPU配置详细说明
- [告警机制说明.md](告警机制说明.md) - 告警机制说明
- 系统日志: `/cv_space/predict/output.log`

---

## 🎉 开始使用

```bash
# 1. 安装依赖
pip install -r requirements_manager.txt

# 2. 启动管理界面
./start_manager.sh

# 3. 打开浏览器
# 访问: http://localhost:8500

# 4. 开始管理你的算法服务！
```

享受便捷的Web管理体验！🚀


